{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, AveragePooling2D, Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.constraints import Constraint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "base_model = VGGFace(model='resnet50', input_tensor=input_tensor, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 2048)   0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          524544      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 7)            1799        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,087,495\n",
      "Trainable params: 526,343\n",
      "Non-trainable params: 23,561,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "x = base_model.output\n",
    "x = AveragePooling2D(pool_size=(7,7), padding='same')(x)\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(7, activation=\"softmax\")(x)\n",
    "\n",
    "updatedModel = Model(base_model.input, x)\n",
    "updatedModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"../Train\"\n",
    "val_folder = \"../Val\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batchsize = 32\n",
    "val_batchsize = 8\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1 , patience = 10)\n",
    "\n",
    "csv_logger = CSVLogger('resnet_training.log', separator=',', append=False)\n",
    "callbacks_list = [reduce_lr, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "learning_rate = 1e-4\n",
    "sgd = SGD(lr=learning_rate, momentum = 0.9)\n",
    "updatedModel.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "898/898 [==============================] - 223s 248ms/step - loss: 2.2641 - acc: 0.2857 - val_loss: 2.0692 - val_acc: 0.4018s: 2\n",
      "Epoch 2/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.6215 - acc: 0.3824 - val_loss: 1.8712 - val_acc: 0.4369\n",
      "Epoch 3/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.5103 - acc: 0.4238 - val_loss: 1.6929 - val_acc: 0.4609\n",
      "Epoch 4/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.4398 - acc: 0.4518 - val_loss: 1.9555 - val_acc: 0.4773\n",
      "Epoch 5/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.3838 - acc: 0.4748 - val_loss: 1.9201 - val_acc: 0.4954\n",
      "Epoch 6/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.3463 - acc: 0.4906 - val_loss: 2.0090 - val_acc: 0.4957\n",
      "Epoch 7/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.3146 - acc: 0.5073 - val_loss: 2.0258 - val_acc: 0.5065\n",
      "Epoch 8/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.2866 - acc: 0.5173 - val_loss: 2.0446 - val_acc: 0.5132\n",
      "Epoch 9/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.2634 - acc: 0.5275 - val_loss: 1.8754 - val_acc: 0.5199\n",
      "Epoch 10/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.2457 - acc: 0.5309 - val_loss: 2.0014 - val_acc: 0.5191\n",
      "Epoch 11/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.2269 - acc: 0.5399 - val_loss: 2.0914 - val_acc: 0.5169\n",
      "Epoch 12/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.2100 - acc: 0.5458 - val_loss: 1.9483 - val_acc: 0.5238\n",
      "Epoch 13/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1916 - acc: 0.5514 - val_loss: 1.9873 - val_acc: 0.5230\n",
      "Epoch 14/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1784 - acc: 0.5595 - val_loss: 2.1288 - val_acc: 0.5235\n",
      "Epoch 15/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1784 - acc: 0.5605 - val_loss: 2.0549 - val_acc: 0.5249\n",
      "Epoch 16/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1728 - acc: 0.5636 - val_loss: 2.0993 - val_acc: 0.5277\n",
      "Epoch 17/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1818 - acc: 0.5624 - val_loss: 2.0020 - val_acc: 0.5224\n",
      "Epoch 18/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1725 - acc: 0.5624 - val_loss: 2.0225 - val_acc: 0.5219\n",
      "Epoch 19/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1706 - acc: 0.5645 - val_loss: 1.8784 - val_acc: 0.5274\n",
      "Epoch 20/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1685 - acc: 0.5657 - val_loss: 2.0529 - val_acc: 0.5241\n",
      "Epoch 21/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1628 - acc: 0.5629 - val_loss: 1.9605 - val_acc: 0.5272\n",
      "Epoch 22/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1672 - acc: 0.5639 - val_loss: 2.0683 - val_acc: 0.5277\n",
      "Epoch 23/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1652 - acc: 0.5648 - val_loss: 2.2406 - val_acc: 0.5230\n",
      "Epoch 24/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1646 - acc: 0.5651 - val_loss: 1.9662 - val_acc: 0.5258\n",
      "Epoch 25/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1630 - acc: 0.5662 - val_loss: 2.0589 - val_acc: 0.5274\n",
      "Epoch 26/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1629 - acc: 0.5683 - val_loss: 2.0137 - val_acc: 0.5238\n",
      "Epoch 27/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1662 - acc: 0.5639 - val_loss: 1.9860 - val_acc: 0.5258\n",
      "Epoch 28/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1609 - acc: 0.5676 - val_loss: 2.1096 - val_acc: 0.5249\n",
      "Epoch 29/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1603 - acc: 0.5658 - val_loss: 2.1349 - val_acc: 0.5238\n",
      "Epoch 30/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1640 - acc: 0.5650 - val_loss: 2.1149 - val_acc: 0.5213\n",
      "Epoch 31/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1611 - acc: 0.5681 - val_loss: 1.9596 - val_acc: 0.5258\n",
      "Epoch 32/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1645 - acc: 0.5684 - val_loss: 2.1615 - val_acc: 0.5280\n",
      "Epoch 33/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1636 - acc: 0.5667 - val_loss: 1.8849 - val_acc: 0.5249\n",
      "Epoch 34/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1655 - acc: 0.5631 - val_loss: 2.0390 - val_acc: 0.5269\n",
      "Epoch 35/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1648 - acc: 0.5652 - val_loss: 1.8852 - val_acc: 0.5269\n",
      "Epoch 36/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1657 - acc: 0.5665 - val_loss: 1.9351 - val_acc: 0.5216\n",
      "Epoch 37/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1694 - acc: 0.5651 - val_loss: 2.0849 - val_acc: 0.5283\n",
      "Epoch 38/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1714 - acc: 0.5622 - val_loss: 2.1885 - val_acc: 0.5205.1718 - acc: 0.5\n",
      "Epoch 39/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1643 - acc: 0.5674 - val_loss: 2.0578 - val_acc: 0.5330\n",
      "Epoch 40/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1655 - acc: 0.5645 - val_loss: 2.0849 - val_acc: 0.5252\n",
      "Epoch 41/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1621 - acc: 0.5679 - val_loss: 2.1885 - val_acc: 0.5208\n",
      "Epoch 42/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1634 - acc: 0.5641 - val_loss: 2.0397 - val_acc: 0.5247\n",
      "Epoch 43/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1622 - acc: 0.5667 - val_loss: 1.8853 - val_acc: 0.5249\n",
      "Epoch 44/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1616 - acc: 0.5651 - val_loss: 1.9629 - val_acc: 0.5249\n",
      "Epoch 45/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1607 - acc: 0.5673 - val_loss: 2.2392 - val_acc: 0.5294\n",
      "Epoch 46/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1645 - acc: 0.5678 - val_loss: 2.0389 - val_acc: 0.5286\n",
      "Epoch 47/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1589 - acc: 0.5694 - val_loss: 1.9629 - val_acc: 0.5300\n",
      "Epoch 48/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1643 - acc: 0.5665 - val_loss: 1.9629 - val_acc: 0.5252\n",
      "Epoch 49/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1691 - acc: 0.5669 - val_loss: 2.0675 - val_acc: 0.5274\n",
      "Epoch 50/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1630 - acc: 0.5650 - val_loss: 2.1107 - val_acc: 0.5199\n",
      "Epoch 51/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1638 - acc: 0.5631 - val_loss: 2.0855 - val_acc: 0.5199\n",
      "Epoch 52/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1618 - acc: 0.5679 - val_loss: 2.0136 - val_acc: 0.5258\n",
      "Epoch 53/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1631 - acc: 0.5642 - val_loss: 1.8844 - val_acc: 0.5258\n",
      "Epoch 54/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1674 - acc: 0.5689 - val_loss: 2.1099 - val_acc: 0.5269\n",
      "Epoch 55/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1639 - acc: 0.5635 - val_loss: 2.0578 - val_acc: 0.5316\n",
      "Epoch 56/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1598 - acc: 0.5664 - val_loss: 2.0855 - val_acc: 0.5302\n",
      "Epoch 57/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1673 - acc: 0.5649 - val_loss: 2.0666 - val_acc: 0.5185\n",
      "Epoch 58/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1615 - acc: 0.5680 - val_loss: 2.0569 - val_acc: 0.5213\n",
      "Epoch 59/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1591 - acc: 0.5664 - val_loss: 2.1107 - val_acc: 0.5208\n",
      "Epoch 60/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1620 - acc: 0.5646 - val_loss: 2.2392 - val_acc: 0.5258\n",
      "Epoch 61/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1578 - acc: 0.5674 - val_loss: 2.1099 - val_acc: 0.5294\n",
      "Epoch 62/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1574 - acc: 0.5677 - val_loss: 2.1355 - val_acc: 0.5297\n",
      "Epoch 63/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1672 - acc: 0.5654 - val_loss: 2.0855 - val_acc: 0.5269\n",
      "Epoch 64/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1609 - acc: 0.5704 - val_loss: 2.0145 - val_acc: 0.5247\n",
      "Epoch 65/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1643 - acc: 0.5670 - val_loss: 1.9881 - val_acc: 0.5210oss: 1.1648 - acc:\n",
      "Epoch 66/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1656 - acc: 0.5646 - val_loss: 2.0145 - val_acc: 0.5258\n",
      "Epoch 67/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1560 - acc: 0.5674 - val_loss: 2.0847 - val_acc: 0.5224\n",
      "Epoch 68/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1685 - acc: 0.5628 - val_loss: 2.1606 - val_acc: 0.5255\n",
      "Epoch 69/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1636 - acc: 0.5655 - val_loss: 2.2400 - val_acc: 0.5208\n",
      "Epoch 70/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1631 - acc: 0.5638 - val_loss: 2.0070 - val_acc: 0.5213\n",
      "Epoch 71/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1697 - acc: 0.5627 - val_loss: 2.0388 - val_acc: 0.5249\n",
      "Epoch 72/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1657 - acc: 0.5649 - val_loss: 2.1174 - val_acc: 0.52476 - \n",
      "Epoch 73/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1670 - acc: 0.5641 - val_loss: 2.0397 - val_acc: 0.5227\n",
      "Epoch 74/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1639 - acc: 0.5654 - val_loss: 2.1182 - val_acc: 0.5280\n",
      "Epoch 75/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1607 - acc: 0.5618 - val_loss: 2.1099 - val_acc: 0.5258\n",
      "Epoch 76/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1624 - acc: 0.5673 - val_loss: 2.0578 - val_acc: 0.5277\n",
      "Epoch 77/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1671 - acc: 0.5640 - val_loss: 2.2400 - val_acc: 0.5305\n",
      "Epoch 78/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1594 - acc: 0.5678 - val_loss: 2.0070 - val_acc: 0.5227\n",
      "Epoch 79/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1648 - acc: 0.5626 - val_loss: 2.0855 - val_acc: 0.5288\n",
      "Epoch 80/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1652 - acc: 0.5688 - val_loss: 2.1174 - val_acc: 0.5205\n",
      "Epoch 81/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1692 - acc: 0.5663 - val_loss: 2.0674 - val_acc: 0.5255ss: 1.1 - ETA: 8s - loss: 1.1697 - acc: 0.5\n",
      "Epoch 82/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1629 - acc: 0.5675 - val_loss: 1.8844 - val_acc: 0.5252\n",
      "Epoch 83/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1643 - acc: 0.5645 - val_loss: 2.0062 - val_acc: 0.5216\n",
      "Epoch 84/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1662 - acc: 0.5667 - val_loss: 2.0578 - val_acc: 0.5266\n",
      "Epoch 85/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1642 - acc: 0.5681 - val_loss: 1.9629 - val_acc: 0.5261\n",
      "Epoch 86/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1681 - acc: 0.5625 - val_loss: 2.1174 - val_acc: 0.5255\n",
      "Epoch 87/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1565 - acc: 0.5672 - val_loss: 2.2400 - val_acc: 0.5249\n",
      "Epoch 88/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1608 - acc: 0.5697 - val_loss: 2.0855 - val_acc: 0.5280\n",
      "Epoch 89/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1623 - acc: 0.5656 - val_loss: 2.0388 - val_acc: 0.5266\n",
      "Epoch 90/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1683 - acc: 0.5642 - val_loss: 2.0070 - val_acc: 0.5316\n",
      "Epoch 91/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1583 - acc: 0.5664 - val_loss: 1.9629 - val_acc: 0.5286\n",
      "Epoch 92/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1629 - acc: 0.5646 - val_loss: 2.1884 - val_acc: 0.5235\n",
      "Epoch 93/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1649 - acc: 0.5661 - val_loss: 2.1107 - val_acc: 0.5308\n",
      "Epoch 94/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1624 - acc: 0.5654 - val_loss: 1.9360 - val_acc: 0.5227\n",
      "Epoch 95/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1628 - acc: 0.5640 - val_loss: 2.1107 - val_acc: 0.5263\n",
      "Epoch 96/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1654 - acc: 0.5625 - val_loss: 2.1355 - val_acc: 0.5230\n",
      "Epoch 97/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1630 - acc: 0.5656 - val_loss: 2.0070 - val_acc: 0.5213\n",
      "Epoch 98/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1594 - acc: 0.5657 - val_loss: 2.0062 - val_acc: 0.5233\n",
      "Epoch 99/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1645 - acc: 0.5649 - val_loss: 2.1363 - val_acc: 0.5336\n",
      "Epoch 100/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1653 - acc: 0.5627 - val_loss: 1.8852 - val_acc: 0.5213\n",
      "Epoch 101/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1671 - acc: 0.5656 - val_loss: 2.0136 - val_acc: 0.5263\n",
      "Epoch 102/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1617 - acc: 0.5638 - val_loss: 2.2392 - val_acc: 0.5222loss: 1.1618 - acc: 0 - ETA: 4s - loss: 1. - ETA: 0s - loss: 1.1617 - acc: 0.5\n",
      "Epoch 103/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1642 - acc: 0.5641 - val_loss: 2.0674 - val_acc: 0.5263\n",
      "Epoch 104/200\n",
      "898/898 [==============================] - 214s 239ms/step - loss: 1.1648 - acc: 0.5646 - val_loss: 2.0136 - val_acc: 0.5283\n",
      "Epoch 105/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1651 - acc: 0.5632 - val_loss: 2.0855 - val_acc: 0.5252\n",
      "Epoch 106/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1656 - acc: 0.5642 - val_loss: 2.1355 - val_acc: 0.5249\n",
      "Epoch 107/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1632 - acc: 0.5652 - val_loss: 2.1606 - val_acc: 0.5238\n",
      "Epoch 108/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1662 - acc: 0.5654 - val_loss: 1.8852 - val_acc: 0.5272\n",
      "Epoch 109/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1645 - acc: 0.5679 - val_loss: 2.1884 - val_acc: 0.5224\n",
      "Epoch 110/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1622 - acc: 0.5649 - val_loss: 2.1606 - val_acc: 0.5274\n",
      "Epoch 111/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1636 - acc: 0.5670 - val_loss: 2.0397 - val_acc: 0.5196\n",
      "Epoch 112/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1607 - acc: 0.5657 - val_loss: 2.0578 - val_acc: 0.5302\n",
      "Epoch 113/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1609 - acc: 0.5665 - val_loss: 2.0062 - val_acc: 0.5297\n",
      "Epoch 114/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1650 - acc: 0.5666 - val_loss: 2.2392 - val_acc: 0.5247\n",
      "Epoch 115/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1615 - acc: 0.5675 - val_loss: 2.0847 - val_acc: 0.5227\n",
      "Epoch 116/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1663 - acc: 0.5652 - val_loss: 2.0397 - val_acc: 0.5252\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1621 - acc: 0.5707 - val_loss: 1.9360 - val_acc: 0.5233s\n",
      "Epoch 118/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1699 - acc: 0.5638 - val_loss: 2.1174 - val_acc: 0.5208\n",
      "Epoch 119/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1628 - acc: 0.5647 - val_loss: 1.9881 - val_acc: 0.5266s - loss: - ETA: 1s - loss: 1.1615 - acc:\n",
      "Epoch 120/200\n",
      "898/898 [==============================] - 215s 239ms/step - loss: 1.1625 - acc: 0.5640 - val_loss: 2.1363 - val_acc: 0.5277\n",
      "Epoch 121/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1642 - acc: 0.5663 - val_loss: 2.2400 - val_acc: 0.5272\n",
      "Epoch 122/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1606 - acc: 0.5659 - val_loss: 2.1182 - val_acc: 0.5280\n",
      "Epoch 123/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1673 - acc: 0.5651 - val_loss: 2.1099 - val_acc: 0.5283\n",
      "Epoch 124/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1689 - acc: 0.5665 - val_loss: 1.8844 - val_acc: 0.5261\n",
      "Epoch 125/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1654 - acc: 0.5647 - val_loss: 2.0070 - val_acc: 0.5222\n",
      "Epoch 126/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1649 - acc: 0.5663 - val_loss: 2.1606 - val_acc: 0.5308\n",
      "Epoch 127/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1626 - acc: 0.5672 - val_loss: 1.9629 - val_acc: 0.5249\n",
      "Epoch 128/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1657 - acc: 0.5653 - val_loss: 1.8844 - val_acc: 0.5233\n",
      "Epoch 129/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1625 - acc: 0.5670 - val_loss: 2.1892 - val_acc: 0.5272\n",
      "Epoch 130/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1648 - acc: 0.5680 - val_loss: 2.0397 - val_acc: 0.5269\n",
      "Epoch 131/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1636 - acc: 0.5640 - val_loss: 2.1615 - val_acc: 0.5213\n",
      "Epoch 132/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1592 - acc: 0.5663 - val_loss: 2.0070 - val_acc: 0.5247\n",
      "Epoch 133/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1599 - acc: 0.5680 - val_loss: 2.0388 - val_acc: 0.5263\n",
      "Epoch 134/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1590 - acc: 0.5681 - val_loss: 2.0145 - val_acc: 0.5235\n",
      "Epoch 135/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1599 - acc: 0.5649 - val_loss: 1.9637 - val_acc: 0.5274\n",
      "Epoch 136/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1617 - acc: 0.5683 - val_loss: 2.0070 - val_acc: 0.5280\n",
      "Epoch 137/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1623 - acc: 0.5655 - val_loss: 2.0674 - val_acc: 0.5247\n",
      "Epoch 138/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1600 - acc: 0.5681 - val_loss: 2.0062 - val_acc: 0.5247\n",
      "Epoch 139/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1630 - acc: 0.5647 - val_loss: 2.0070 - val_acc: 0.5297\n",
      "Epoch 140/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1556 - acc: 0.5687 - val_loss: 1.9637 - val_acc: 0.5247\n",
      "Epoch 141/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1605 - acc: 0.5673 - val_loss: 2.0388 - val_acc: 0.5238\n",
      "Epoch 142/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1617 - acc: 0.5662 - val_loss: 1.9881 - val_acc: 0.5238\n",
      "Epoch 143/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1614 - acc: 0.5662 - val_loss: 2.2400 - val_acc: 0.5255\n",
      "Epoch 144/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1644 - acc: 0.5642 - val_loss: 1.9351 - val_acc: 0.5258\n",
      "Epoch 145/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1560 - acc: 0.5681 - val_loss: 2.1615 - val_acc: 0.5283\n",
      "Epoch 146/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1702 - acc: 0.5640 - val_loss: 1.9629 - val_acc: 0.5252\n",
      "Epoch 147/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1634 - acc: 0.5638 - val_loss: 2.1099 - val_acc: 0.5208\n",
      "Epoch 148/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1642 - acc: 0.5655 - val_loss: 2.0145 - val_acc: 0.5263\n",
      "Epoch 149/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1642 - acc: 0.5662 - val_loss: 1.9351 - val_acc: 0.5205\n",
      "Epoch 150/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1568 - acc: 0.5680 - val_loss: 2.1892 - val_acc: 0.5291\n",
      "Epoch 151/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1603 - acc: 0.5669 - val_loss: 1.9889 - val_acc: 0.5272\n",
      "Epoch 152/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1639 - acc: 0.5659 - val_loss: 2.0388 - val_acc: 0.5291\n",
      "Epoch 153/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1646 - acc: 0.5659 - val_loss: 2.1099 - val_acc: 0.5219\n",
      "Epoch 154/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1618 - acc: 0.5682 - val_loss: 2.0855 - val_acc: 0.5244\n",
      "Epoch 155/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1698 - acc: 0.5625 - val_loss: 2.0062 - val_acc: 0.5213\n",
      "Epoch 156/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1636 - acc: 0.5636 - val_loss: 2.1355 - val_acc: 0.5233\n",
      "Epoch 157/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1676 - acc: 0.5641 - val_loss: 1.9629 - val_acc: 0.5297\n",
      "Epoch 158/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1708 - acc: 0.5604 - val_loss: 2.1363 - val_acc: 0.5196\n",
      "Epoch 159/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1594 - acc: 0.5649 - val_loss: 1.9637 - val_acc: 0.5247\n",
      "Epoch 160/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1640 - acc: 0.5646 - val_loss: 1.9637 - val_acc: 0.5305\n",
      "Epoch 161/200\n",
      "898/898 [==============================] - 215s 240ms/step - loss: 1.1633 - acc: 0.5668 - val_loss: 2.0062 - val_acc: 0.5160\n",
      "Epoch 162/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1665 - acc: 0.5650 - val_loss: 2.1615 - val_acc: 0.5213\n",
      "Epoch 163/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1626 - acc: 0.5674 - val_loss: 2.0855 - val_acc: 0.5230\n",
      "Epoch 164/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1655 - acc: 0.5649 - val_loss: 1.9637 - val_acc: 0.5196\n",
      "Epoch 165/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1646 - acc: 0.5637 - val_loss: 2.0578 - val_acc: 0.5327\n",
      "Epoch 166/200\n",
      "898/898 [==============================] - 216s 241ms/step - loss: 1.1664 - acc: 0.5670 - val_loss: 2.1606 - val_acc: 0.5277\n",
      "Epoch 167/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1583 - acc: 0.5676 - val_loss: 2.1174 - val_acc: 0.5235\n",
      "Epoch 168/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1629 - acc: 0.5685 - val_loss: 2.1182 - val_acc: 0.5288ss: 1.1632 - acc: 0.5 - ETA: 0s - loss: 1.1631 - acc: 0.56\n",
      "Epoch 169/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1695 - acc: 0.5602 - val_loss: 2.1099 - val_acc: 0.5235\n",
      "Epoch 170/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1711 - acc: 0.5686 - val_loss: 2.0145 - val_acc: 0.5202\n",
      "Epoch 171/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1574 - acc: 0.5706 - val_loss: 2.1107 - val_acc: 0.5258\n",
      "Epoch 172/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1628 - acc: 0.5660 - val_loss: 2.1174 - val_acc: 0.5255\n",
      "Epoch 173/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1607 - acc: 0.5675 - val_loss: 1.9637 - val_acc: 0.5210\n",
      "Epoch 174/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1601 - acc: 0.5672 - val_loss: 2.0666 - val_acc: 0.5244\n",
      "Epoch 175/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1638 - acc: 0.5669 - val_loss: 1.9360 - val_acc: 0.5297\n",
      "Epoch 176/200\n",
      "898/898 [==============================] - 216s 241ms/step - loss: 1.1673 - acc: 0.5613 - val_loss: 2.0145 - val_acc: 0.5224\n",
      "Epoch 177/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1625 - acc: 0.5636 - val_loss: 1.9629 - val_acc: 0.5258\n",
      "Epoch 178/200\n",
      "898/898 [==============================] - 216s 241ms/step - loss: 1.1627 - acc: 0.5648 - val_loss: 2.0847 - val_acc: 0.5227\n",
      "Epoch 179/200\n",
      "898/898 [==============================] - 216s 241ms/step - loss: 1.1574 - acc: 0.5695 - val_loss: 2.2392 - val_acc: 0.5269\n",
      "Epoch 180/200\n",
      "898/898 [==============================] - 216s 241ms/step - loss: 1.1606 - acc: 0.5659 - val_loss: 2.0569 - val_acc: 0.527712s -  - ETA: 9s - loss: 1.1591 - ac\n",
      "Epoch 181/200\n",
      "898/898 [==============================] - 216s 241ms/step - loss: 1.1721 - acc: 0.5622 - val_loss: 2.0070 - val_acc: 0.5238\n",
      "Epoch 182/200\n",
      "898/898 [==============================] - 216s 241ms/step - loss: 1.1639 - acc: 0.5686 - val_loss: 2.0666 - val_acc: 0.5263\n",
      "Epoch 183/200\n",
      "898/898 [==============================] - 216s 241ms/step - loss: 1.1614 - acc: 0.5634 - val_loss: 2.0666 - val_acc: 0.5286\n",
      "Epoch 184/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1640 - acc: 0.5656 - val_loss: 2.0062 - val_acc: 0.5230\n",
      "Epoch 185/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1627 - acc: 0.5662 - val_loss: 1.8852 - val_acc: 0.5252\n",
      "Epoch 186/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1626 - acc: 0.5661 - val_loss: 1.9889 - val_acc: 0.5205\n",
      "Epoch 187/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1669 - acc: 0.5668 - val_loss: 1.9351 - val_acc: 0.5263\n",
      "Epoch 188/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1708 - acc: 0.5606 - val_loss: 2.0070 - val_acc: 0.5227\n",
      "Epoch 189/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1641 - acc: 0.5640 - val_loss: 2.1182 - val_acc: 0.5272\n",
      "Epoch 190/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1629 - acc: 0.5641 - val_loss: 2.0569 - val_acc: 0.5210 - acc: 0.\n",
      "Epoch 191/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1605 - acc: 0.5706 - val_loss: 2.0847 - val_acc: 0.5247\n",
      "Epoch 192/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1619 - acc: 0.5678 - val_loss: 1.9889 - val_acc: 0.5249\n",
      "Epoch 193/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1638 - acc: 0.5653 - val_loss: 2.1182 - val_acc: 0.5283\n",
      "Epoch 194/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1620 - acc: 0.5676 - val_loss: 2.0070 - val_acc: 0.5283\n",
      "Epoch 195/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1600 - acc: 0.5648 - val_loss: 2.1107 - val_acc: 0.5233\n",
      "Epoch 196/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1623 - acc: 0.5647 - val_loss: 1.8852 - val_acc: 0.5202\n",
      "Epoch 197/200\n",
      "898/898 [==============================] - 216s 240ms/step - loss: 1.1615 - acc: 0.5648 - val_loss: 1.9637 - val_acc: 0.5244\n",
      "Epoch 198/200\n",
      "898/898 [==============================] - 216s 241ms/step - loss: 1.1648 - acc: 0.5636 - val_loss: 2.0062 - val_acc: 0.5249\n",
      "Epoch 199/200\n",
      "898/898 [==============================] - 216s 241ms/step - loss: 1.1638 - acc: 0.5674 - val_loss: 2.0145 - val_acc: 0.5266\n",
      "Epoch 200/200\n",
      "898/898 [==============================] - 216s 241ms/step - loss: 1.1656 - acc: 0.5686 - val_loss: 2.1606 - val_acc: 0.5244\n"
     ]
    }
   ],
   "source": [
    "history = updatedModel.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "updatedModel.save('../saves/ResNet50.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(validations, predictions, labels):\n",
    "\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(matrix,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"../Test\"\n",
    "IMAGE_SIZE = 224\n",
    "random.seed(3)\n",
    "test_batchsize = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../saves/ResNet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=test_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = test_generator.classes\n",
    "label2index = test_generator.class_indices\n",
    "idx2label = dict((v, k) for k, v in label2index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589/3589 [==============================] - 76s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(test_generator,\n",
    "                      steps=test_generator.samples / test_generator.batch_size,\n",
    "                      verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of errors = 1617/3589\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.51      0.49       464\n",
      "           1       0.02      0.50      0.04         2\n",
      "           2       0.23      0.30      0.26       405\n",
      "           3       0.80      0.82      0.81       849\n",
      "           4       0.54      0.56      0.55       605\n",
      "           5       0.63      0.39      0.48       970\n",
      "           6       0.47      0.67      0.55       294\n",
      "\n",
      "    accuracy                           0.55      3589\n",
      "   macro avg       0.45      0.54      0.46      3589\n",
      "weighted avg       0.58      0.55      0.55      3589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "errors = np.where(predicted_classes != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors), test_generator.samples))\n",
    "labels = [\"angry\", \"disgust\", \"fear\", \"happy\", \"normal\", \"sad\", \"surprise\"]\n",
    "show_confusion_matrix(predicted_classes, ground_truth, labels)\n",
    "print(classification_report(predicted_classes, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase SPARSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import deserialize as layer_from_config\n",
    "from keras.models import model_from_config\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, AveragePooling2D, Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  load_model('../saves/ResNet50.hdf5')\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "sparse_model = VGGFace(model='resnet50', input_tensor=input_tensor, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 8, 11, 12, 17, 20, 23, 27, 30, 33, 37, 40, 43, 44, 49, 52, 55, 59, 62, 65, 69, 72, 75, 79, 82, 85, 86, 91, 94, 97, 101, 104, 107, 111, 114, 117, 121, 124, 127, 131, 134, 137, 141, 144, 147, 148, 153, 156, 159, 163, 166, 169]\n"
     ]
    }
   ],
   "source": [
    "layers = sparse_model.layers\n",
    "pos = []\n",
    "val = 0\n",
    "for layer in layers:\n",
    "    string = str(layer)\n",
    "    if 'Conv2D' in string:\n",
    "        pos.append(val)\n",
    "    val = val + 1\n",
    "print(pos)\n",
    "\n",
    "config = sparse_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'input_2', 'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 224, 224, 3), 'dtype': 'float32', 'sparse': False, 'name': 'input_2'}, 'inbound_nodes': []}\n"
     ]
    }
   ],
   "source": [
    "print(config['layers'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sparse(Constraint):\n",
    "    def __init__(self, mask):\n",
    "        self.mask = K.cast_to_floatx(mask)\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        return self.mask * x\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'mask': self.mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparsity_masks(model,sparsity):\n",
    "    weights_list = model.get_weights()\n",
    "    masks = []\n",
    "    for weights in weights_list:\n",
    "        #We can ignore biases\n",
    "        if len(weights.shape) > 1:\n",
    "            weights_abs = np.abs(weights)\n",
    "            masks.append((weights_abs>np.percentile(weights_abs,sparsity))*1.)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = create_sparsity_masks(model,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sparse_model.output\n",
    "x = AveragePooling2D(pool_size=(7, 7), padding='same')(x)\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(7, activation=\"softmax\")(x)\n",
    "\n",
    "sparse_model= Model(sparse_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 55, 55, 256)  0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 55, 55, 256)  0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 55, 55, 256)  0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 28, 28, 512)  0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 28, 28, 512)  0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 28, 28, 512)  0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 28, 28, 512)  0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 14, 14, 1024) 0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 14, 14, 1024) 0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 14, 14, 1024) 0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 14, 14, 1024) 0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 14, 14, 1024) 0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 14, 14, 1024) 0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 7, 7, 2048)   0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 7, 7, 2048)   0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 7, 7, 2048)   0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 1, 1, 2048)   0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          524544      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 256)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 7)            1799        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,087,495\n",
      "Trainable params: 526,343\n",
      "Non-trainable params: 23,561,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers = sparse_model.layers\n",
    "layers = layers[0:173]\n",
    "for layer in layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "count = 0\n",
    "for n in pos:\n",
    "    layers[n].kernel_constraint = Sparse(masks[count])\n",
    "    count = count + 1\n",
    "\n",
    "sparse_model.set_weights(model.get_weights())\n",
    "\n",
    "sparse_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"C:/Users/nico9/Desktop/FaceDetection/Train\"\n",
    "val_folder = \"C:/Users/nico9/Desktop/FaceDetection/Val\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batchsize = 32\n",
    "val_batchsize = 8\n",
    "IMAGE_SIZE = 224\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1 , patience = 10)\n",
    "\n",
    "csv_logger = CSVLogger('resnet_sparse_training.log', separator=',', append=False)\n",
    "callbacks_list = [reduce_lr, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('../notebook/resnet_training.log')\n",
    "dim = len(log['lr'])\n",
    "lr = log['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = lr[dim-1]\n",
    "sgd = SGD(lr=learning_rate, momentum = 0.9)\n",
    "sparse_model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = sparse_model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "sparse_model.save('../saves/resnet_sparse_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot fase Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test fase Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(validations, predictions, labels):\n",
    "\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(matrix,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"../Test\"\n",
    "IMAGE_SIZE = 224\n",
    "random.seed(3)\n",
    "test_batchsize = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../saves/resnet_sparse_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=test_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = test_generator.classes\n",
    "label2index = test_generator.class_indices\n",
    "idx2label = dict((v, k) for k, v in label2index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator,\n",
    "                      steps=test_generator.samples / test_generator.batch_size,\n",
    "                      verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.where(predicted_classes != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors), test_generator.samples))\n",
    "labels = [\"angry\", \"disgust\", \"fear\", \"happy\", \"normal\", \"sad\", \"surprise\"]\n",
    "show_confusion_matrix(predicted_classes, ground_truth, labels)\n",
    "print(classification_report(predicted_classes, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seconda fase Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_model = load_model('../saves/resnet_sparse_model.hdf5')\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "base_model = VGGFace(model='resnet50', input_tensor=input_tensor, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "x = base_model.output\n",
    "x = AveragePooling2D(pool_size=(7,7), padding='same')(x)\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(7, activation=\"softmax\")(x)\n",
    "\n",
    "updatedModel = Model(base_model.input, x)\n",
    "updatedModel.set_weights(sparse_model.get_weights())\n",
    "updatedModel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"../Train\"\n",
    "val_folder = \"../Val\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batchsize = 32\n",
    "val_batchsize = 8\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1 , patience = 10)\n",
    "\n",
    "csv_logger = CSVLogger('redense_resnet_training.log', separator=',', append=False)\n",
    "callbacks_list = [reduce_lr, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('../notebook/resnet_sparse_training.log')\n",
    "dim = len(log['lr'])\n",
    "lr = log['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = lr[dim-1]\n",
    "sgd = SGD(lr=learning_rate, momentum = 0.9)\n",
    "updatedModel.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = updatedModel.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "updatedModel.save('../saves/redense_ResNet50.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot seconda fase Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test seconda fase Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(validations, predictions, labels):\n",
    "\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(matrix,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"../Test\"\n",
    "IMAGE_SIZE = 224\n",
    "random.seed(3)\n",
    "test_batchsize = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../saves/redense_ResNet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=test_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = test_generator.classes\n",
    "label2index = test_generator.class_indices\n",
    "idx2label = dict((v, k) for k, v in label2index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator,\n",
    "                      steps=test_generator.samples / test_generator.batch_size,\n",
    "                      verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.where(predicted_classes != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors), test_generator.samples))\n",
    "labels = [\"angry\", \"disgust\", \"fear\", \"happy\", \"normal\", \"sad\", \"surprise\"]\n",
    "show_confusion_matrix(predicted_classes, ground_truth, labels)\n",
    "print(classification_report(predicted_classes, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seconda fase Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  load_model('../saves/redense_ResNet50.hdf5')\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "sparse_model = VGGFace(model='resnet50', input_tensor=input_tensor, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = sparse_model.layers\n",
    "pos = []\n",
    "val = 0\n",
    "for layer in layers:\n",
    "    string = str(layer)\n",
    "    if 'Conv2D' in string:\n",
    "        pos.append(val)\n",
    "    val = val + 1\n",
    "print(pos)\n",
    "\n",
    "config = sparse_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sparse(Constraint):\n",
    "    def __init__(self, mask):\n",
    "        self.mask = K.cast_to_floatx(mask)\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        return self.mask * x\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'mask': self.mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparsity_masks(model,sparsity):\n",
    "    weights_list = model.get_weights()\n",
    "    masks = []\n",
    "    for weights in weights_list:\n",
    "        #We can ignore biases\n",
    "        if len(weights.shape) > 1:\n",
    "            weights_abs = np.abs(weights)\n",
    "            masks.append((weights_abs>np.percentile(weights_abs,sparsity))*1.)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = create_sparsity_masks(model,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sparse_model.output\n",
    "x = AveragePooling2D(pool_size=(7, 7), padding='same')(x)\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(7, activation=\"softmax\")(x)\n",
    "\n",
    "sparse_model= Model(sparse_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = sparse_model.layers\n",
    "layers = layers[0:173]\n",
    "for layer in layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "count = 0\n",
    "for n in pos:\n",
    "    layers[n].kernel_constraint = Sparse(masks[count])\n",
    "    count = count + 1\n",
    "\n",
    "sparse_model.set_weights(model.get_weights())\n",
    "\n",
    "sparse_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"C:/Users/nico9/Desktop/FaceDetection/Train\"\n",
    "val_folder = \"C:/Users/nico9/Desktop/FaceDetection/Val\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batchsize = 32\n",
    "val_batchsize = 8\n",
    "IMAGE_SIZE = 224\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1 , patience = 10)\n",
    "\n",
    "csv_logger = CSVLogger('resnet_sparse2_training.log', separator=',', append=False)\n",
    "callbacks_list = [reduce_lr, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('../notebook/redense_resnet_training.log')\n",
    "dim = len(log['lr'])\n",
    "lr = log['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = lr[dim-1]\n",
    "sgd = SGD(lr=learning_rate, momentum = 0.9)\n",
    "sparse_model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = sparse_model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "sparse_model.save('../saves/resnet_sparse2_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot seconda fase Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test seconda fase Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(validations, predictions, labels):\n",
    "\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(matrix,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"../Test\"\n",
    "IMAGE_SIZE = 224\n",
    "random.seed(3)\n",
    "test_batchsize = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../saves/resnet_sparse2_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=test_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = test_generator.classes\n",
    "label2index = test_generator.class_indices\n",
    "idx2label = dict((v, k) for k, v in label2index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator,\n",
    "                      steps=test_generator.samples / test_generator.batch_size,\n",
    "                      verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.where(predicted_classes != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors), test_generator.samples))\n",
    "labels = [\"angry\", \"disgust\", \"fear\", \"happy\", \"normal\", \"sad\", \"surprise\"]\n",
    "show_confusion_matrix(predicted_classes, ground_truth, labels)\n",
    "print(classification_report(predicted_classes, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terza fase Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_model = load_model('../saves/resnet_sparse2_model.hdf5')\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "base_model = VGGFace(model='resnet50', input_tensor=input_tensor, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "x = base_model.output\n",
    "x = AveragePooling2D(pool_size=(7,7), padding='same')(x)\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(7, activation=\"softmax\")(x)\n",
    "\n",
    "updatedModel = Model(base_model.input, x)\n",
    "updatedModel.set_weights(sparse_model.get_weights())\n",
    "updatedModel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"../Train\"\n",
    "val_folder = \"../Val\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batchsize = 32\n",
    "val_batchsize = 8\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1 , patience = 10)\n",
    "\n",
    "csv_logger = CSVLogger('dense3_resnet_training.log', separator=',', append=False)\n",
    "callbacks_list = [reduce_lr, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('../notebook/resnet_sparse2_training.log')\n",
    "dim = len(log['lr'])\n",
    "lr = log['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = lr[dim-1]\n",
    "sgd = SGD(lr=learning_rate, momentum = 0.9)\n",
    "updatedModel.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = updatedModel.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "updatedModel.save('../saves/dense3_ResNet50.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot terza fase Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test terza Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(validations, predictions, labels):\n",
    "\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(matrix,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"../Test\"\n",
    "IMAGE_SIZE = 224\n",
    "random.seed(3)\n",
    "test_batchsize = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../saves/dense3_ResNet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_folder,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=test_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = test_generator.classes\n",
    "label2index = test_generator.class_indices\n",
    "idx2label = dict((v, k) for k, v in label2index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator,\n",
    "                      steps=test_generator.samples / test_generator.batch_size,\n",
    "                      verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.where(predicted_classes != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors), test_generator.samples))\n",
    "labels = [\"angry\", \"disgust\", \"fear\", \"happy\", \"normal\", \"sad\", \"surprise\"]\n",
    "show_confusion_matrix(predicted_classes, ground_truth, labels)\n",
    "print(classification_report(predicted_classes, ground_truth))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
